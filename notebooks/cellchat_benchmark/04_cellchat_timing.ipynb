{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env Rscript\n",
    "'Time how long it takes to run cellchat given some samples\n",
    "Usage:\n",
    "    Rscript 04_cellchat_timing.r --number=<int> --group=<bool> [--seed=<int>]\n",
    "    \n",
    "Options:\n",
    "    -h --help  Show this screen.\n",
    "    --number=<int>  number of samples to include\n",
    "    --group=<bool>  whether to group by context (1) or keep separated by samples (0)\n",
    "    --seed=<int>  set a seed for random graph generation \n",
    "' -> doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "allied-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘docopt’ was built under R version 4.0.5”\n"
     ]
    }
   ],
   "source": [
    "suppressPackageStartupMessages({\n",
    "    library(CellChat, quietly = T)\n",
    "    library(patchwork, quietly = T)\n",
    "    library(RhpcBLASctl, quietly = T)\n",
    "    library(Matrix, quietly = T)\n",
    "    library(docopt, quietly = T)\n",
    "    library(rhdf5, quietly = T)\n",
    "    library(stringr, quietly = T)\n",
    "})\n",
    "options(stringsAsFactors = FALSE)\n",
    "# expression_data_path = '/data2/hratch/immune_CCI/covid/covid_atlas/interim/umi_for_timing/'\n",
    "input_path = '/data2/hratch/immune_CCI/covid/covid_atlas/interim/timing_inputs/'\n",
    "\n",
    "RhpcBLASctl::blas_set_num_threads(1) # no multithreading\n",
    "\n",
    "# parameters\n",
    "cell_grouper<-'majorType'\n",
    "type_<-'functional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = docopt(doc)\n",
    "for (opt in c('number', 'group', 'seed')){\n",
    "    val = opts[[opt]]\n",
    "    if (!is.null(val)){\n",
    "        opts[[opt]] = as.numeric(val)\n",
    "        }}\n",
    "\n",
    "number<-opts[['number']]\n",
    "group<-opts[['group']]\n",
    "seed<-opts[['seed']]\n",
    "set.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-moses",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loaded-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples<-read.csv(paste0(input_path, 'samples_for_timing.csv'))\n",
    "sample.names<-unlist(strsplit(samples[samples$n_samples == number, 'sample_names'], '; '))\n",
    "\n",
    "# load LR pairs\n",
    "# filter for the LR pairs used by Tensor cell2cell\n",
    "# lr_pairs<-read.csv(paste0(input_data_path,'Tensor-cell2cell-LRpairs.csv'))\n",
    "# lr_pairs<-lr_pairs$interaction_name\n",
    "humandb<-CellChatDB.human\n",
    "# humandb$interaction<-CellChatDB.human$interaction[CellChatDB.human$interaction$interaction_name %in% lr_pairs, ] \n",
    "# saveRDS(humandb, paste0(output_results_path, 'humandb.rds'))\n",
    "\n",
    "# load metadata\n",
    "md.cell <- read.csv(paste0(input_path,'metadata_for_timing.csv'), row.names = 1)\n",
    "sample_context_map<-readRDS(paste0(input_path, 'sample_context_map.rds'))\n",
    "contexts<-unique(sample_context_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjusted-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the UMI counts\n",
    "read_sample_h5<-function(sn){\n",
    "    counts<-h5read(paste0(input_path, 'umi_per_sample.h5'), sn)\n",
    "    count<-counts[[4]]\n",
    "    colnames(count)<-counts[[2]]\n",
    "    rownames(count)<-sapply(counts[[1]], function(x) str_replace_all(x, '-', '.')) \n",
    "    return(count)\n",
    "}\n",
    "\n",
    "\n",
    "if (!group){                             \n",
    "    counts<-lapply(setNames(sample.names, sample.names), function(sn) read_sample_h5(sn))\n",
    "                                  \n",
    "}else{ # group by context\n",
    "    by.context<-lapply(setNames(contexts, contexts), function(context) names(sample_context_map[sample.names][sample_context_map[sample.names] == context]))\n",
    "    \n",
    "    group_by_context<-function(context){\n",
    "        sns<-by.context[[context]]       \n",
    "        counts<-lapply(sns, function(sn) read_sample_h5(sn))    \n",
    "        counts<-do.call(cbind, counts)\n",
    "        return (counts)\n",
    "    }\n",
    "    counts<-lapply(setNames(contexts, contexts), function(context) group_by_context(context))                   \n",
    "                    \n",
    "}\n",
    "                   \n",
    "# filter for intersection of cell types across samples/contexts - to make comparable with Tensor-cell2cell\n",
    "# cell.types<-Reduce(intersect, lapply(sample.names, function(sn) unique(md.cell[md.cell$sampleID == sn, cell_grouper])))\n",
    "cell.types<-Reduce(intersect, lapply(counts, function(df) unique(md.cell[colnames(df), cell_grouper])))\n",
    "cell.ids<-rownames(md.cell[md.cell[[cell_grouper]] %in% cell.types, ])   \n",
    "# counts<-lapply(setNames(counts, counts), function(df) df[,colnames(df) %in% cell.ids])  # lapply version slow for some reason, see for loop below                    \n",
    "for (n in names(counts)){\n",
    "    df<-counts[[n]]\n",
    "    counts[[n]]<-df[,colnames(df) %in% cell.ids]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-atmosphere",
   "metadata": {},
   "source": [
    "Run cellchat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "restricted-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Rank the similarity of the shared signaling pathways based on their joint manifold learning\n",
    "#'\n",
    "#' @param object CellChat object\n",
    "#' @param slot.name the slot name of object that is used to compute centrality measures of signaling networks\n",
    "#' @param type \"functional\",\"structural\"\n",
    "#' @param comparison1 a numerical vector giving the datasets for comparison. This should be the same as `comparison` in `computeNetSimilarityPairwise`\n",
    "#' @param comparison2 a numerical vector with two elements giving the datasets for comparison.\n",
    "#'\n",
    "#' If there are more than 2 datasets defined in `comparison1`, `comparison2` can be defined to indicate which two datasets used for computing the distance.\n",
    "#' e.g., comparison2 = c(1,3) indicates the first and third datasets defined in `comparison1` will be used for comparison.\n",
    "#' @import ggplot2\n",
    "#' @importFrom methods slot\n",
    "#' @return\n",
    "#' @export\n",
    "#'\n",
    "#' @examples\n",
    "rankSimilarity_ <- function(object, slot.name = \"netP\", type = c(\"functional\",\"structural\"), comparison1 = NULL,  \n",
    "                           comparison2 = c(1,2)) {\n",
    "  type <- match.arg(type)\n",
    "\n",
    "  if (is.null(comparison1)) {\n",
    "    comparison1 <- 1:length(unique(object@meta$datasets))\n",
    "  }\n",
    "  comparison.name <- paste(comparison1, collapse = \"-\")\n",
    "  cat(\"Compute the distance of signaling networks between datasets\", as.character(comparison1[comparison2]), '\\n')\n",
    "  comparison2.name <- names(methods::slot(object, slot.name))[comparison1[comparison2]]\n",
    "\n",
    "  Y <- methods::slot(object, slot.name)$similarity[[type]]$dr[[comparison.name]]\n",
    "  group <- sub(\".*--\", \"\", rownames(Y))\n",
    "  data1 <- Y[group %in% comparison2.name[1], ]\n",
    "  data2 <- Y[group %in% comparison2.name[2], ]\n",
    "  rownames(data1) <- sub(\"--.*\", \"\", rownames(data1))\n",
    "  rownames(data2) <- sub(\"--.*\", \"\", rownames(data2))\n",
    "\n",
    "  pathway.show = as.character(intersect(rownames(data1), rownames(data2)))\n",
    "  data1 <- data1[pathway.show, ]\n",
    "  data2 <- data2[pathway.show, ]\n",
    "  euc.dist <- function(x1, x2) sqrt(sum((x1 - x2) ^ 2))\n",
    "  dist <- NULL\n",
    "  for(i in 1:nrow(data1)) dist[i] <- euc.dist(data1[i,],data2[i,])\n",
    "  df <- data.frame(name = pathway.show, dist = dist, row.names = pathway.show)\n",
    "  df <- df[order(df$dist), , drop = F]\n",
    "  df$name <- factor(df$name, levels = as.character(df$name))\n",
    "\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "based-location",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create a CellChat object from a data matrix\n",
      "\n",
      "Set cell identities for the new CellChat object\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cell groups used for CellChat analysis are  B CD4 CD8 DC Mega Mono NK Plasma \n",
      "The cell-cell communication related with the following cell groups are excluded due to the few number of cells:  Mega Plasma \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create a CellChat object from a data matrix\n",
      "\n",
      "Set cell identities for the new CellChat object\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cell groups used for CellChat analysis are  B CD4 CD8 DC Mega Mono NK Plasma \n",
      "The cell-cell communication related with the following cell groups are excluded due to the few number of cells:  Mega Plasma \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create a CellChat object from a data matrix\n",
      "\n",
      "Set cell identities for the new CellChat object\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cell groups used for CellChat analysis are  B CD4 CD8 DC Mega Mono NK Plasma \n",
      "The cell-cell communication related with the following cell groups are excluded due to the few number of cells:  Mega Plasma \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merge the following slots: 'data.signaling','net', 'netP','meta', 'idents', 'var.features' , 'DB', and 'LR'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute signaling network similarity for datasets 1 2 3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n",
      "Warning message in sqrt((entropia((Pg + Ph)/2) - (entropia(pg) + entropia(ph))/2)/log(2)):\n",
      "“NaNs produced”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifold learning of the signaling networks for datasets 1 2 3 \n",
      "Classification learning of the signaling networks for datasets 1 2 3 \n",
      "Compute the distance of signaling networks between datasets 1 2 \n",
      "Compute the distance of signaling networks between datasets 1 3 \n",
      "Compute the distance of signaling networks between datasets 2 3 \n"
     ]
    }
   ],
   "source": [
    "# create cellchat object for each sample or sample.name\n",
    "covid.list<-list()\n",
    "for (sample.name in names(counts)){\n",
    "    # loop through each sample.name and create a cell type future\n",
    "    expr<-CellChat::normalizeData(counts[[sample.name]])\n",
    "    cellchat<-createCellChat(object = as(expr, \"dgCMatrix\"), meta = md.cell[colnames(expr),], \n",
    "                                   group.by = cell_grouper)\n",
    "    cellchat@DB <- humandb # human organism\n",
    "\n",
    "    cellchat <- subsetData(cellchat) # subset the expression data of signaling genes, assign to @data.signalling \n",
    "    cellchat <- identifyOverExpressedGenes(cellchat)\n",
    "    cellchat <- identifyOverExpressedInteractions(cellchat) # generate @ LR slot used by computeCommunProb\n",
    "    cellchat <- projectData(cellchat, PPI.human) # shallow sequencing depth\n",
    "    \n",
    "    cellchat <- computeCommunProb(cellchat, raw.use = F, type = 'triMean', trim = NULL, seed.use = seed, \n",
    "                                 population.size = F) \n",
    "    \n",
    "    # The functional similarity analysis requires the same cell population composition between two datasets.\n",
    "    cellchat <- filterCommunication(cellchat, min.cells = 10)\n",
    "    cellchat <- computeCommunProbPathway(cellchat)\n",
    "    covid.list[[sample.name]]<-cellchat\n",
    "}\n",
    "\n",
    "# merge and analyze\n",
    "cellchat <- mergeCellChat(covid.list, add.names = names(covid.list))\n",
    "cellchat <- computeNetSimilarityPairwise(cellchat, type = type_)\n",
    "cellchat <- netEmbedding(cellchat, type = type_)\n",
    "cellchat <- netClustering(cellchat, type = type_,  do.parallel = F, do.plot = F)\n",
    "# Manifold learning of the signaling networks for datasets \n",
    "pairwise_comparisons<-sapply(as.data.frame(combn(seq(1:length(covid.list)),2)), \n",
    "                         function(x) as.numeric(x), simplify = F) # pairwise combination of elements\n",
    "\n",
    "for (pc in names(pairwise_comparisons)){\n",
    "    path.dist<-rankSimilarity_(cellchat, type = type_, comparison1 = 1:length(covid.list),\n",
    "                               comparison2 = pairwise_comparisons[[pc]]) \n",
    "}                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-appeal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:cellchat]",
   "language": "R",
   "name": "conda-env-cellchat-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
