{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interesting-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "# import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_path = '/data2/hratch/immune_CCI/covid/covid_atlas/'\n",
    "load_h5 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbmc_covid = sc.read_mtx(data_path + 'raw/GSE158055_covid19_counts.mtx.gz') # raw counts\n",
    "if load_h5: \n",
    "    pch5 = sc.read_h5ad(data_path + 'raw/COVID19_ALL.h5ad') # load dataset\n",
    "# pbmc_covid = sc.read_10x_mtx(data_path + 'raw/counts/')\n",
    "\n",
    "print('Finished loading covid datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude samples with fewer than 2000 cells\n",
    "md_cell = pd.read_csv(data_path + 'raw/GSE158055_cell_annotation.csv.gz')\n",
    "n_samples = md_cell.sampleID.value_counts()\n",
    "samples_to_keep = n_samples[n_samples > 2000].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_excel(data_path + 'raw/GSE158055_sample_metadata.xlsx', sheet_name = 0, skiprows=20)\n",
    "md = md.iloc[range(304 - 20), range(25)]\n",
    "md = md[md['Sample name'].isin(samples_to_keep)] # >2000 cellcs\n",
    "md = md[md['characteristics: Sample type'].isin(['frozen PBMC', 'fresh PBMC'])] # pbmcs only\n",
    "\n",
    "contexts = md['characteristics: CoVID-19 severity'].unique()\n",
    "n_contexts = contexts.shape[0]\n",
    "\n",
    "context_counts = md['characteristics: CoVID-19 severity'].value_counts() \n",
    "min_context_type = context_counts[context_counts == context_counts.min()].index.tolist()[0]\n",
    "min_context_count = len(md[md['characteristics: CoVID-19 severity'] == min_context_type]['Patients'].unique())\n",
    "\n",
    "max_samples = min_context_count*n_contexts\n",
    "\n",
    "context_map = {context: md[md['characteristics: CoVID-19 severity'] == \\\n",
    "                           context][['Sample name', 'Patients']].reset_index(drop = True) for context in contexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select samples subsetted from the entire dataset\n",
    "# make sure to choose an even number of each context\n",
    "# make sure not to repeat patients within a context\n",
    "\n",
    "n_iter = 1 # number of times to run subsetting\n",
    "seed = 0\n",
    "\n",
    "Samples = pd.DataFrame(columns = ['iteration', 'n_samples', 'sample_names'])\n",
    "idx = 0\n",
    "\n",
    "sample_iters = [3, 6, 12, 24, 36, 48, 60]#list(range(n_contexts, max_samples + 1, n_contexts))\n",
    "\n",
    "for iteration in range(n_iter):\n",
    "    for n_samples in sample_iters:\n",
    "        cmap_temp = context_map.copy()\n",
    "        n_sample_per_context = int(n_samples/n_contexts)\n",
    "        samples = list()\n",
    "        for context in contexts:\n",
    "            df = context_map[context].sample(frac=1, random_state = seed).drop_duplicates(subset = 'Patients') # shuffle rows to randomly drop duplicates\n",
    "            samples += df.sample(n = n_sample_per_context, random_state = seed)['Sample name'].tolist()\n",
    "            seed += 1\n",
    "        Samples.loc[idx,:] = [iteration, n_samples, samples]\n",
    "        idx += 1\n",
    "\n",
    "Samples['sample_names'] = Samples.sample_names.apply(lambda x: '; '.join(x))            \n",
    "Samples.to_csv(data_path + 'interim/timing_inputs/samples_for_timing.csv')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell_ids = pd.read_csv(data_path + 'raw/GSE158055_covid19_barcodes.tsv.gz', header = None)\n",
    "gene_ids = pd.read_csv(data_path + 'raw/GSE158055_covid19_features.tsv.gz', header = None)\n",
    "md_cell.set_index('cellName', drop = True, inplace = True)\n",
    "\n",
    "pbmc_covid = pbmc_covid.transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_h5:\n",
    "    pbmc_covid.obs = pch5.obs\n",
    "    pbmc_covid.var = pch5.var\n",
    "else:\n",
    "    pbmc_covid.obs = md_cell\n",
    "    pbmc_covid.var = gene_ids.set_index(0, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-desktop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split by sample id \n",
    "\n",
    "def flatten_list(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def create_raw_counts(sample_id):\n",
    "    df = pbmc_covid[pbmc_covid.obs.sampleID == sample_id]\n",
    "    sc.pp.filter_cells(df, min_genes=50) \n",
    "#     sc.pp.filter_genes(df, min_cells = 3) # avoid filtering genes, will need intersection of remaining genes, which filters to many out when subsequently filtering for LR pairs\n",
    "    return df\n",
    "\n",
    "sample_ids = list(set(flatten_list([sn.split('; ') for sn in Samples.sample_names.tolist()])))\n",
    "sample_counts = {sample_id: create_raw_counts(sample_id) for sample_id in tqdm(sample_ids)}\n",
    "\n",
    "\n",
    "min_cells_to_keep = min([df.n_obs for sample_id, df in sample_counts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-mambo",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# seed = 21\n",
    "seed += 1\n",
    "\n",
    "# subset to min cells_to_keep and write to csv\n",
    "cells_to_keep = list()\n",
    "for sample_id in tqdm(sample_counts):\n",
    "    random.seed(seed)\n",
    "    df = sample_counts[sample_id]\n",
    "    df = df[df.obs.index.isin(random.sample(df.obs.index.tolist(), min_cells_to_keep))] # subset\n",
    "#     df.to_df().to_csv(data_path + 'interim/umi_for_timing/' + sample_id + '.csv') # write\n",
    "    df.to_df().to_hdf(data_path + 'interim/timing_inputs/umi_per_sample.h5', key = sample_id)\n",
    "    cells_to_keep += df.obs.index.tolist()\n",
    "    seed += 1\n",
    "\n",
    "pbmc_covid.obs[pbmc_covid.obs.index.isin(cells_to_keep)].to_csv(data_path + 'interim/timing_inputs/metadata_for_timing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-release",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = md['Sample name'].unique().tolist()\n",
    "pbmc_covid.obs[pbmc_covid.obs.sampleID.isin(sample_ids)].to_csv(data_path + 'interim/classification_inputs/metadata.csv')\n",
    "sample_counts = {sample_id: create_raw_counts(sample_id) for sample_id in tqdm(sample_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_id in tqdm(sample_counts):\n",
    "    df = sample_counts[sample_id]\n",
    "#     df.to_df().to_csv(data_path + 'interim/umi_for_classification/' + sample_id + '.csv') # write\n",
    "    df.to_df().to_hdf(data_path + 'interim/classification_inputs/umi_per_sample.h5', key = sample_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cellchat] *",
   "language": "python",
   "name": "conda-env-cellchat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
