{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decimal-irish",
   "metadata": {},
   "source": [
    "Run tensor cell2cell on outputs of various communication scoring tools\n",
    "\n",
    "env name: cci_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wired-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cell2cell as c2c\n",
    "\n",
    "seed = 888\n",
    "np.random.seed(seed)\n",
    "\n",
    "rev_path = '/data3/hratch/tc2c_analyses_1/natcomm_revisions/'\n",
    "scores_path = rev_path + 'interim/tc2c_external_inputs/liana/liana_outputs/'\n",
    "\n",
    "cp_delim = '-'\n",
    "lr_delim = '&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greek-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/hratch/Projects/CCC/tc2c_analyses_1/notebooks/natcomm_revisions/')\n",
    "from utility import edgelist_to_communication_matrix, matrix_to_interaction_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intelligent-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_methods = {file_name.split('_')[-1].split('.csv')[0] for file_name in os.listdir(scores_path)}\n",
    "samples = {file_name.split('_')[0] for file_name in os.listdir(scores_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "palestinian-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the method-specific column names for the edge list\n",
    "score_labels = {'natmi': {'score': 'edge_specificity', \n",
    "                            'sender': 'source', 'receiver': 'target', \n",
    "                            'ligand': 'ligand.complex', 'receptor': 'receptor.complex'}, \n",
    "               'cellchat': {'score': 'prob', \n",
    "                            'sender': 'source', 'receiver': 'target', \n",
    "                            'ligand': 'ligand', 'receptor': 'receptor'}, \n",
    "               'cellphonedb': {'score': 'lr.mean', \n",
    "                            'sender': 'source', 'receiver': 'target', \n",
    "                            'ligand': 'ligand.complex', 'receptor': 'receptor.complex'}, \n",
    "               'sca': {'score': 'LRscore', \n",
    "                            'sender': 'source', 'receiver': 'target', \n",
    "                            'ligand': 'ligand.complex', 'receptor': 'receptor.complex'}\n",
    "               }\n",
    "#                'connectome': {'score': 'weight_sc', \n",
    "#                             'sender': 'source', 'receiver': 'target', \n",
    "#                             'ligand': 'ligand.complex', 'receptor': 'receptor.complex'}, \n",
    "#                'logfc': {'score': 'logfc_comb', \n",
    "#                             'sender': 'source', 'receiver': 'target', \n",
    "#                             'ligand': 'ligand.complex', 'receptor': 'receptor.complex'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "superior-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_redundant_complexes(edge_list, score_method):\n",
    "    \"\"\"some complexes generated redundant rows due to distinct ligands or receptors\n",
    "    double check that the communication score is the same b/w redundant complex rows\n",
    "    then drop those duplicated scores.\"\"\"\n",
    "    \n",
    "    dup_cols = list(score_labels[score_method].values())\n",
    "    dup_cols.remove(score_labels[score_method]['score'])\n",
    "    dup_idx = edge_list[edge_list[dup_cols].duplicated(subset = dup_cols)].index.tolist()\n",
    "\n",
    "    for i in dup_idx:\n",
    "        dup_val = edge_list.loc[i, dup_cols]\n",
    "        unique_scores = edge_list[(edge_list[dup_cols[0]] == dup_val.loc[dup_cols[0]]) & \n",
    "                 (edge_list[dup_cols[1]] == dup_val.loc[dup_cols[1]]) & \n",
    "                 (edge_list[dup_cols[2]] == dup_val.loc[dup_cols[2]]) & \n",
    "                 (edge_list[dup_cols[3]] == dup_val.loc[dup_cols[3]])][score_labels[score_method]['score']].unique()\n",
    "        if len(unique_scores) > 1:\n",
    "            raise ValueError('Unexpected inconsistency in communication scores b/w complexs')\n",
    "\n",
    "\n",
    "    el = edge_list.drop_duplicates(subset = dup_cols) \n",
    "    return el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edgelist to communication matrix for all contexts/methods\n",
    "score_matrices = dict()\n",
    "\n",
    "for score_method in score_methods:\n",
    "    for sample in samples:\n",
    "        edge_list = pd.read_csv(scores_path + ''.join([sample, '_communication_scores_', score_method, '.csv']))\n",
    "        edge_list = drop_redundant_complexes(edge_list, score_method)\n",
    "\n",
    "\n",
    "        cm = edgelist_to_communication_matrix(edge_list, \n",
    "                                        score_col = score_labels[score_method]['score'], \n",
    "                                        sender_cell_col = score_labels[score_method]['sender'], \n",
    "                                        receiver_cell_col = score_labels[score_method]['receiver'], \n",
    "                                        ligand_col = score_labels[score_method]['ligand'], \n",
    "                                        receptor_col = score_labels[score_method]['receptor'])\n",
    "        if score_method in score_matrices:\n",
    "            score_matrices[score_method][sample] = cm\n",
    "        else:\n",
    "            score_matrices[score_method] = {sample: cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "proud-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  4.45it/s]\n",
      "/home/hratch/anaconda3/envs/cci_dt/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3427: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.60it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 79.83it/s]\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.43it/s]\n"
     ]
    }
   ],
   "source": [
    "tensors = {}\n",
    "for method, scores in score_matrices.items():\n",
    "    tensors[method] = matrix_to_interaction_tensor(scores=scores, \n",
    "                             lr_how = 'inner', cell_how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix matrix_to_interaction_tensor context orders\n",
    "# take inner of all tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "commercial-delta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 6, 54, 12), (6, 6, 53, 12), (5, 5, 3, 12), (6, 6, 54, 12)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tensor.tensor.shape for tensor in tensors.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "reduced-commercial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tensors['cellchat'].order_names[2]).difference(tensors['natmi'].order_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "textile-publication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cellphonedb', 'natmi', 'cellchat', 'sca'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liana::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors['natmi'].tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "conscious-tokyo",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-ec21299bde3e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-ec21299bde3e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    resource %<>% select_resource\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-authorization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape tensor\n",
    "# make sure consistent, and with correct order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-style",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amazing-combination",
   "metadata": {},
   "source": [
    "Transform into 4D Interaction Tensor\n",
    "Make all communication matrices consistent -- contain all same LR and CC pairs in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "retained-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all possible cell type pairs -- union of all LR pairs and CC pairs measured by all methods\n",
    "\n",
    "# # only necessary bc multiple pipelines, otherwise can feed directly into \"matrix_to_communication_tensor\" with how = 'outer'\n",
    "# score_methods = [cellchat, ]\n",
    "# method_names = ['cellchat', ]\n",
    "\n",
    "\n",
    "# cell_pairs = []\n",
    "# lr_pairs = []\n",
    "# for score_method in score_methods:\n",
    "#     cp = [df.columns.tolist() for df in score_method.values()]\n",
    "#     cp = [item for sublist in cp for item in sublist]\n",
    "#     cell_pairs += cp\n",
    "    \n",
    "#     lr = [df.index.tolist() for df in score_method.values()]\n",
    "#     lr = [item for sublist in lr for item in sublist]\n",
    "#     lr_pairs += lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "compatible-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_pairs = sorted(set(cell_pairs))\n",
    "# lr_pairs = sorted(set(lr_pairs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "taken-prime",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellchat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:24<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# def create_nan_vals_all(df, lr_pairs, cell_pairs):\n",
    "#     \"\"\"Adds nan communication scores if pipeline did not include a certain sender-receiver cell pair\"\"\"\n",
    "#     df = pd.concat([df, pd.DataFrame(index = set(lr_pairs).difference(df.index),columns = df.columns)])\n",
    "#     for col in set(cell_pairs).difference(df.columns):\n",
    "#         df[col] = float('nan')\n",
    "    \n",
    "#     df = df.loc[lr_pairs, cell_pairs] # make the order the same\n",
    "#     return df\n",
    "\n",
    "# tensors = {}\n",
    "# for idx, score_method in enumerate(score_methods):\n",
    "#     print(method_names[idx])\n",
    "#     scores = OrderedDict({k: create_nan_vals_all(df=score_method[k], lr_pairs=lr_pairs, cell_pairs=cell_pairs) for k in samples})\n",
    "#     score_methods[idx] = scores\n",
    "#     tensors[method_names[idx]] = matrix_to_interaction_tensor(scores, how = 'outer', \n",
    "#                                                              cp_delim='-', lr_delim='&')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cci_dt] *",
   "language": "python",
   "name": "conda-env-cci_dt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
